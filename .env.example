# API Keys (NEVER commit .env.local - keep keys secret!)
VITE_API_URL=http://localhost:3000

# LLM Provider Keys (stored server-side only)
# Currently using Groq API with llama-3.1-8b-instant model
GROQ_API_KEY=your_groq_api_key_here
GROQ_MODEL=llama-3.1-8b-instant

# Alternative providers (not currently used)
OPENAI_API_KEY=your_openai_api_key_here
ANTHROPIC_API_KEY=your_anthropic_api_key_here
COHERE_API_KEY=your_cohere_api_key_here

# Rate Limiting Configuration
RATE_LIMIT_REQUESTS_PER_MINUTE=20
RATE_LIMIT_REQUESTS_PER_HOUR=200
RATE_LIMIT_WINDOW_MS=60000

# Request Size Limits
MAX_REQUEST_SIZE_MB=1
MAX_TOKENS_PER_REQUEST=4000

# Logging & Monitoring
SENTRY_DSN=your_sentry_dsn_here
LOG_LEVEL=info
ENABLE_DETAILED_LOGGING=false

# Database (optional - for storing logs)
SUPABASE_URL=your_supabase_url
SUPABASE_ANON_KEY=your_supabase_key

# Cache Configuration
# Enable/disable cache (default: true)
CACHE_ENABLED=true

# Redis URL for distributed cache (optional - falls back to in-memory)
# Local: redis://localhost:6379
# Upstash: rediss://default:password@host:port
REDIS_URL=

# Cache TTL in seconds (default: 86400 = 24 hours)
CACHE_TTL_SECONDS=86400

# Version tracking for cache invalidation
MODEL_VERSION=llama-3.1-8b-instant-v1
RAG_VERSION=1.0.0

# Admin API key for cache management endpoints
ADMIN_API_KEY=your-secret-admin-key-here
